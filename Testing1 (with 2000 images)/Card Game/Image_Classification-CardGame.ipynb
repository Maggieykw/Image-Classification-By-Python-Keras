{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Overview:\n",
    "#[1] using anaconda (which installed TensorFlow)\n",
    "#[2] train a model for image classification\n",
    "#[3] process image classification of selected product (from SQL query result)\n",
    "#[4] store result into a csv file\n",
    "\n",
    "###For training model\n",
    "#Before running code:\n",
    "#[1] download train_network.py if you want to run function of \"train_network_sample\" (for running sample from online: https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/)\n",
    "#[2] open a file called \"images\" (inside working directory) containing two subfiles (rename them as two groups for classification; \"boardgame\" & \"not_boardgame\" in this case) \n",
    "#[3] collect large quantity of pictures (two groups for classification) by Fatkun (https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf)\n",
    "#[4] put the pictures into corresponding subfiles (500 for each subfiles in this case)\n",
    "\n",
    "#Required file: \n",
    "#[1]lenet.py\n",
    "#[2]train_network.py; \n",
    "#[3]file called \"images\" having two subfiles (one for excluded group; one for not excluded group; containing certain number of picture inside each subfile)\n",
    "\n",
    "#Running code: \n",
    "#[1] import required module (making sure it is installed)\n",
    "#[2] set directory to the file storing related files\n",
    "#[3] run lenet.py\n",
    "#[4] run function of \"train_network_sample\" OR function of \"train_network(dataset,ExcludedGroup)\"\n",
    "\n",
    "#Output (inside working directory): \n",
    "#[1] a graph of training loss and accuracy on two groups; \n",
    "#[2] BoardGame_Not_BoardGame.model (in this case; will be used for testing)\n",
    "\n",
    "#Remark:\n",
    "#I used function of \"train_network_sample\" to test if the online code works\n",
    "#hence, it is better to use function of \"train_network(dataset,ExcludedGroup)\" for our image classification\n",
    "\n",
    "###For Image Classification (=testing model)\n",
    "#Before running code:\n",
    "#[1] run the above code for training model to create a model\n",
    "#[2] select field \"name\" & \"imgs\" from top100 table in SQL (see attached code 1)\n",
    "#[3] export the query result into \"query_result.csv\"\n",
    "#[4] inside the csv file, expand column of \"imgs\" to columns(-->data-->text to columns) \n",
    "#[5] run VBA for \"query_result.csv\" (see attached code 2) as we want to one column of name and one column of url instead of multiply columns of url each row of name\n",
    "\n",
    "#Required file: \n",
    "#[1] BoardGame_Not_BoardGame.model (in this case; will be used for testing)\n",
    "#[2] query_result.csv\n",
    "\n",
    "#Running code: \n",
    "#[1] import required module (making sure it is installed)\n",
    "#[2] run all the function mentioned below (run main function at last)\n",
    "\n",
    "#Output (inside working directory): \n",
    "#[1] img01.jpg (for working, will be deleted at the end)\n",
    "#[2] ImageClassiferResult.csv (containing product name, img url, classified group & similarity)\n",
    "\n",
    "#Remark:\n",
    "#None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /anaconda3/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "#Upgrade pip\n",
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install required module to run function called train_network(OR train_network.py)\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install h5py\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install -U scikit-learn\n",
    "!{sys.executable} -m pip install imutils\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image\n",
      "  Downloading image-1.5.20-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /anaconda3/envs/tensorflow/lib/python3.6/site-packages/Pillow-4.1.1-py3.6-macosx-10.7-x86_64.egg (from image)\n",
      "Collecting django (from image)\n",
      "  Downloading Django-2.0.3-py3-none-any.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 166kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: olefile in /anaconda3/envs/tensorflow/lib/python3.6/site-packages/olefile-0.45.1-py3.6.egg (from pillow->image)\n",
      "Requirement already satisfied: pytz in /anaconda3/envs/tensorflow/lib/python3.6/site-packages (from django->image)\n",
      "Installing collected packages: django, image\n",
      "Successfully installed django-2.0.3 image-1.5.20\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install extra module to run function called test_network (OR test_network.py)\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-0.22.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: pytz>=2011k in /anaconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /anaconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /anaconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/envs/tensorflow/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-0.22.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install extra module to run function called rawdata\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!reload(sys)\n",
    "!sys.setdefaultencoding('utf8')\n",
    "\n",
    "#Used to solve error \"Matplotlib is building the font cache using fc-list mac python\" when running train_network.py\n",
    "#https://askubuntu.com/questions/788487/when-trying-to-import-matplotlib-pyplot-get-unicodedecodeerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages (rawdata)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import the necessary packages (train_network)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np #mentioned above\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os #also for remove img\n",
    "\n",
    "#import the necessary packages (convertGIFtoJPG)\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# import the necessary packages (test_network)\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "#import numpy as np #mentioned above\n",
    "#import argparse #mentioned above\n",
    "import imutils\n",
    "#import cv2 #mentioned above\n",
    "import urllib.request, io\n",
    "\n",
    "#import the necessary packages (downloadIMGfromURL)\n",
    "#import urllib.request #mentioned above\n",
    "\n",
    "#import the necessary packages (csv writing and appending)\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kawaiyim/FYP/Image classification:recognition/3rd Method(Keras)/image-classification-keras_FYP\n"
     ]
    }
   ],
   "source": [
    "#Set directory to the file storing train_network.py\n",
    "%cd /Users/kawaiyim/FYP/Image classification:recognition/3rd Method(Keras)/image-classification-keras_FYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lenet.py #For training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawdata():\n",
    "    df = pd.read_csv('query_result.csv')\n",
    "    ListOfProductName = df['name'].tolist()\n",
    "    ListOfURL = df['imgs'].tolist()\n",
    "    \n",
    "    return(ListOfProductName,ListOfURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Result_write_csv():\n",
    "    with open(\"ImageClassiferResult.csv\",\"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file,delimiter=',')\n",
    "        writer.writerow([\"Product Name\",\"img\",\"Assigned Group\",\"Similarity(%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataset are derived from a file called \"images\" including two files storing images of each group respectively\n",
    "def train_network_sample():\n",
    "    %run train_network.py --dataset images --model CardGame_Not_CardGame.model\n",
    "\n",
    "#train_network_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.6828 - acc: 0.6296 - val_loss: 0.6641 - val_acc: 0.7480\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 5s 107ms/step - loss: 0.6530 - acc: 0.8339 - val_loss: 0.6342 - val_acc: 0.8920\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 0.6276 - acc: 0.9142 - val_loss: 0.6062 - val_acc: 0.9680\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 5s 110ms/step - loss: 0.5993 - acc: 0.9789 - val_loss: 0.5801 - val_acc: 0.9900\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 5s 116ms/step - loss: 0.5761 - acc: 0.9878 - val_loss: 0.5558 - val_acc: 0.9960\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 0.5550 - acc: 0.9939 - val_loss: 0.5330 - val_acc: 0.9960\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 5s 108ms/step - loss: 0.5332 - acc: 0.9980 - val_loss: 0.5112 - val_acc: 0.9960\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 5s 115ms/step - loss: 0.5115 - acc: 0.9993 - val_loss: 0.4908 - val_acc: 0.9960\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 0.4949 - acc: 0.9986 - val_loss: 0.4717 - val_acc: 0.9960\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 5s 111ms/step - loss: 0.4755 - acc: 0.9993 - val_loss: 0.4535 - val_acc: 1.0000\n",
      "[INFO] serializing network...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CardGame_Not_CardGame.model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset are derived from a file called \"images\" including two files storing images of each group respectively\n",
    "def train_network(group1,group2,dataset,ExcludedGroup):\n",
    "    \n",
    "    Excluded = ExcludedGroup\n",
    "    NotExcluded = \"Not_\" + ExcludedGroup\n",
    "    \n",
    "    modelName = Excluded+\"_\"+NotExcluded+\".model\"\n",
    "\n",
    "    #group1 = \"board game\"\n",
    "    #group2 = \"not board game\"\n",
    "    # set the matplotlib backend so figures can be saved in the background\n",
    "    #matplotlib.use(\"Agg\") #typed in the above code already\n",
    "    \n",
    "    # initialize the number of epochs to train for, initia learning rate,\n",
    "    # and batch size\n",
    "    EPOCHS = 10\n",
    "    INIT_LR = 1e-3\n",
    "    BS = 32\n",
    "\n",
    "    # initialize the data and labels\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        label = 1 if label == group1 else 0\n",
    "        labels.append(label)\n",
    "\n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # partition the data into training and testing splits using 75% of\n",
    "    # the data for training and the remaining 25% for testing\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data,\n",
    "        labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    trainY = to_categorical(trainY, num_classes=2)\n",
    "    testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "    # construct the image generator for data augmentation\n",
    "    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "        horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "    # initialize the model\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = LeNet.build(width=28, height=28, depth=3, classes=2)\n",
    "    #opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS) #from original code but it is not suitable\n",
    "    opt = SGD(lr=0.00001, momentum=0.4)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "        validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "        epochs=EPOCHS, verbose=1)\n",
    "\n",
    "    # save the model to disk\n",
    "    print(\"[INFO] serializing network...\")\n",
    "    model.save(modelName)\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    N = EPOCHS\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on \" + group1 + \"/\" + group2)\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"plot.png\")\n",
    "    \n",
    "    return modelName\n",
    "\n",
    "train_network(\"card game\",\"not card game\",\"images\",\"CardGame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertGIFtoJPG(url,imgName):\n",
    "    #convert url to gif\n",
    "    uri = url\n",
    "    with open('img01.gif', 'wb') as f:\n",
    "        f.write(requests.get(url).content)\n",
    "\n",
    "    #convert gif to jpg\n",
    "    try:\n",
    "        infile = 'img01.gif'\n",
    "        outfile = imgName #'img01.jpg'\n",
    "\n",
    "        Image.open(infile).convert('RGB').save(outfile)\n",
    "        \n",
    "        remove_img(infile)\n",
    "\n",
    "    except IOError:\n",
    "        print (\"Cannot convert\" ,infile)\n",
    "\n",
    "#testing:\n",
    "#url = 'https://ksr-ugc.imgix.net/assets/014/389/156/e0c5c001a0812a5cf82a56b9f2f80f2f_original.gif?w=680&fit=max&v=1478266603&auto=format&frame=1&q=92&s=f1bfa0c754658e00c4e4533edb56b027'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadIMGfromURL(url,imgName):\n",
    "    try:\n",
    "        #if the image is jpg format\n",
    "        if \"jpg\" in url:\n",
    "            urllib.request.urlretrieve(url,imgName) \n",
    "        else:\n",
    "        #if the image is gif format --> additional work: convert it to jpg before image classification\n",
    "            convertGIFtoJPG(url,imgName)\n",
    "    except:\n",
    "        print('Web site does not exist') \n",
    "\n",
    "#downloadIMGfromURL(\"https://ksr-ugc.imgix.net/assets/005/758/590/b5a0093a9ac8ff1f3ac6062809528b26_original.jpg?w=680&fit=max&v=1461065941&auto=format&q=92&s=973542e86a2f4cef497f2a728e522af5\",\"img01.jpg\") #for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(group1,group2,modelName,imgName):\n",
    "    \n",
    "    #group1 = \"board game\"\n",
    "    #group2 = \"not board game\"\n",
    "\n",
    "    # load the image\n",
    "    image = cv2.imread(imgName)\n",
    "    orig = image.copy()\n",
    "\n",
    "    # pre-process the image for classification\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # load the trained convolutional neural network\n",
    "    print(\"[INFO] loading network...\")\n",
    "    model = load_model(modelName)\n",
    "\n",
    "    # classify the input image\n",
    "    (notExcluded, Excluded) = model.predict(image)[0]\n",
    "\n",
    "    # build the label\n",
    "    result = []\n",
    "    label = group1 if Excluded > notExcluded else group2\n",
    "    proba = Excluded if Excluded > notExcluded else notExcluded\n",
    "\n",
    "    prob=float(\"{0:.2f}\".format(proba * 100))\n",
    "\n",
    "    result.append(label)\n",
    "    result.append(prob)\n",
    "    \n",
    "    label = \"{}: {:.2f}%\".format(label, proba * 100)\n",
    "\n",
    "    # draw the label on the image\n",
    "    #output = imutils.resize(orig, width=400)\n",
    "    #cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # show the output image\n",
    "    #cv2.imshow(\"Output\", output)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#test_network(\"BoardGame_Not_BoardGame.model\",\"img01.jpg\") #testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Result_append_csv(data,ProductName,imgURL):\n",
    "    with open(\"ImageClassiferResult.csv\",\"a\") as csv_file:\n",
    "        result=[]\n",
    "        if data:\n",
    "                result.append(ProductName)\n",
    "                result.append(imgURL)\n",
    "                result = result + data\n",
    "        else:\n",
    "                result.append(ProductName)\n",
    "                \n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_img(imgName):\n",
    "# check if file exists or not\n",
    "    if os.path.exists(imgName) is True:\n",
    "        os.remove(imgName)\n",
    "    else:\n",
    "        # file did not exists\n",
    "        pass\n",
    "\n",
    "#remove_img(\"img01.jpg\") #for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rawdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f68447e8ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-2f68447e8ea7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mListOfProductName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mListOfIMGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mResult_write_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rawdata' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ListOfProductName = rawdata()[0]\n",
    "    ListOfIMGS = rawdata()[1]\n",
    "    \n",
    "    Result_write_csv()\n",
    "    \n",
    "    #Used for function of train_network & test_network, change the name if necessary\n",
    "    group1 = \"card game\"\n",
    "    group2 = \"not card game\"\n",
    "    \n",
    "    #Train a model (did before runing code)\n",
    "    #datasetFile = \"images\"\n",
    "    #ExcludedGroup = \"BoardGame\"\n",
    "    #modelName = train_network(group1,group2,datasetFile,ExcludedGroup)\n",
    "    modelName = \"CardGame_Not_CardGame.model\" #Inside working directory\n",
    "    \n",
    "    x=0\n",
    "    \n",
    "    for url in ListOfIMGS:\n",
    "        \n",
    "        #Store the corresponding product name\n",
    "        ProductName = ListOfProductName[x]\n",
    "\n",
    "        #Store it as img01.jpg inside working directory after downloading picture from url\n",
    "        imgName = \"img01.jpg\" \n",
    "        \n",
    "        #Download the picture from url\n",
    "        downloadIMGfromURL(url,imgName)\n",
    "        \n",
    "        #Image classification and write the result into csv\n",
    "        Result_append_csv(test_network(group1,group2,modelName,imgName),ProductName,url)\n",
    "        \n",
    "        #Remove the picture\n",
    "        remove_img(imgName)\n",
    "        \n",
    "        x+=1\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tutorial: https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "test_network(\"card game\",\"not card game\",\"CardGame_Not_CardGame.model\",\"testing1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
